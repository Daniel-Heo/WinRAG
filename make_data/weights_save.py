from transformers import AutoModel
import numpy as np

# # ðŸ”¹ ì‚¬ìš©í•  ëª¨ë¸ (DeepSeek-R1 14B)
MODEL_NAME = "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = AutoModel.from_pretrained(MODEL_NAME, output_hidden_states=True)

# ìž„ë² ë”© ë ˆì´ì–´ ê°€ì¤‘ì¹˜ ì¶”ì¶œ ë° ì €ìž¥
embedding_weights = model.get_input_embeddings().weight.detach().cpu().numpy()

# 8192 ì°¨ì›ì„ 4ê°œì”© í‰ê· ë‚´ì–´ 2048 ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ : 2.5G(8192) -> 625M(2048) -> 312M(1024) -> 156M(512)
# (152064, 8192) -> (152064, 2048)
compressed_weights = embedding_weights.reshape(152064, 2048, 4).mean(axis=2)

# float16ìœ¼ë¡œ ë³€í™˜
embedding_weights_fp16 = compressed_weights.astype(np.float16)

print("ðŸ”¹ ìž„ë² ë”© ê°€ì¤‘ì¹˜ ë³€í™˜ ì™„ë£Œ:", embedding_weights_fp16.shape)

np.save("embedding_weights.npy", embedding_weights_fp16)  # Numpy ë°°ì—´ë¡œ ì €ìž¥